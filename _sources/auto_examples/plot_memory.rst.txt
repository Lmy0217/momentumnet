
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_memory.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_memory.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_memory.py:


==================================
Plotting memory consumptions
==================================

This example compares memory used when using a ResNet or a Momentum ResNet as a function of their depth

.. GENERATED FROM PYTHON SOURCE LINES 9-28

.. code-block:: default


    # Authors: Michael Sander, Pierre Ablin
    # License: MIT

    import torch
    import torch.nn as nn
    from momentumnet import MomentumNet, Mom
    import matplotlib.pyplot as plt
    from memory_profiler import memory_usage
    import numpy as np
    import os

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


    if not os.path.isdir("figures"):
        os.mkdir("figures")









.. GENERATED FROM PYTHON SOURCE LINES 29-31

Fix random seed for reproducible figures
##########################################

.. GENERATED FROM PYTHON SOURCE LINES 31-34

.. code-block:: default


    torch.manual_seed(1)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <torch._C.Generator object at 0x7ff76f369b30>



.. GENERATED FROM PYTHON SOURCE LINES 35-37

Parameters of the simulation
#############################

.. GENERATED FROM PYTHON SOURCE LINES 37-102

.. code-block:: default



    Depths = np.arange(1, 300, 100)


    hidden = 8
    gamma = 0.99
    d = 500

    function = nn.Sequential(nn.Linear(d, hidden), nn.Tanh(), nn.Linear(hidden, d))
    function_res = nn.Sequential(
        nn.Linear(d, hidden), nn.Tanh(), nn.Linear(hidden, d)
    )

    X = torch.rand(500, 500)


    def train(net):
        Loss = (net(X) ** 2).mean()
        Loss.backward()


    if __name__ == "__main__":
        Mem_list_mom = []

        for n_iters in Depths:
            mom_net = Mom(
                [
                    function,
                ]
                * n_iters,
                gamma=1 - 1 / (50 * n_iters),
                init_speed=0,
            )
            used_mem = np.max(memory_usage((train, (mom_net,))))
            Mem_list_mom.append(used_mem)

        Mem_list_res = []

        for n_iters in Depths:
            res_net = MomentumNet(
                [
                    function_res,
                ],
                gamma=0.0,
                n_iters=n_iters,
                learn_gamma=False,
                init_speed=0,
            )
            used_mem = np.max(memory_usage((train, (res_net,))))
            Mem_list_res.append(used_mem)

        plt.figure(figsize=(4, 1.5))

        plt.plot(
            Depths, Mem_list_res, label="ResNet", linewidth=4, color="darkblue"
        )
        plt.plot(
            Depths, Mem_list_mom, label="MomentumNet", linewidth=4, color="red"
        )
        plt.yscale("log")
        y_ = plt.ylabel("Memory (MiB)")
        x_ = plt.xlabel("Depth")
        plt.legend()
        plt.show()



.. image:: /auto_examples/images/sphx_glr_plot_memory_001.png
    :alt: plot memory
    :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  1.133 seconds)


.. _sphx_glr_download_auto_examples_plot_memory.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_memory.py <plot_memory.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_memory.ipynb <plot_memory.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
