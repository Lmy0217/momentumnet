{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# From ResNets to Momentum ResNets 3)\n\nThis illustrates on a more complex example how to replace an existing\nResNet with a MomentumNet.\n\n\nMichael E. Sander, Pierre Ablin, Mathieu Blondel,\nGabriel Peyre. Momentum Residual Neural Networks.\nProceedings of the 38th International Conference \non Machine Learning, PMLR 139:9276-9287\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Michael Sander, Pierre Ablin\n# License: MIT\nimport torch\nfrom momentumnet import transform_to_momentumnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We will use a Vision Transformer model\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From https://arxiv.org/abs/2010.11929\nCode adapted from https://github.com/lucidrains/vit-pytorch\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from vit_pytorch import ViT\n\nv = ViT(\n    image_size=256,\n    patch_size=32,\n    num_classes=1000,\n    dim=1024,\n    depth=6,\n    heads=16,\n    mlp_dim=2048,\n    dropout=0.1,\n    emb_dropout=0.1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first rename transformer layer from v to be\nconsistent with our forward rule\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v.transformer = v.transformer.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We simply modify the transformer module to have a\nSequential form\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v_modules = []\nfor i, _ in enumerate(v.transformer):\n    for layer in v.transformer[i]:\n        v_modules.append(layer)\n\nv.transformer = torch.nn.Sequential(*v_modules)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can transform it to its momentum version\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mv = transform_to_momentumnet(\n    v,\n    [\"transformer\"],\n    gamma=0.9,\n    keep_first_layer=False,\n    use_backprop=False,\n    is_residual=True,\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}