{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Momentum ResNets on a digit learning task\n\nIn this example we train a Momentum ResNet and a ResNet\non the sklearn digit dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Michael Sander, Pierre Ablin\n# License: MIT\n\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nimport numpy as np\nimport torch.optim as optim\n\nfrom momentumnet import MomentumNet\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\n\ntorch.manual_seed(1)\nnp.random.seed(1)\n\nX, y = load_digits(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, shuffle=True\n)\n\nX_train = torch.tensor(X_train).float()\nX_test = torch.tensor(X_test).float()\ny_train = torch.tensor(y_train)\ny_test = torch.tensor(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architecture\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hidden = 32\nn_iters = 10\nN = 1000\nd = X.shape[-1]\n\nfunctions = [\n    nn.Sequential(nn.Linear(d, hidden), nn.Tanh(), nn.Linear(hidden, d))\n    for _ in range(n_iters)\n]\n\n# Network\nmresnet = MomentumNet(functions, gamma=0.5)\n\nnet = nn.Sequential(mresnet, nn.Linear(64, 10))\ncriterion = nn.CrossEntropyLoss()\n\nn_epochs = 75\nlr_list = np.ones(n_epochs) * 0.01\n\noptimizer = optim.Adam(mresnet.parameters(), lr=lr_list[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_error_mresnet = []\nfor i in range(n_epochs):\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr_list[i]\n    optimizer.zero_grad()\n    output = mresnet(X_train)\n    loss = criterion(output, y_train)\n    loss.backward()\n    optimizer.step()\n    if i % 30 == 0:\n        print(\"itr %s, loss = %.3f\" % (i, loss.item()))\n        print(\"- \" * 20)\n    _, pred = mresnet(X_test).max(1)\n    test_error_mresnet.append(\n        (1 - pred.eq(y_test).sum().item() / y_test.shape[0]) * 100\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Same for a ResNet\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "functions = [\n    nn.Sequential(nn.Linear(d, hidden), nn.Tanh(), nn.Linear(hidden, d))\n    for _ in range(n_iters)\n]\n\nresnet = MomentumNet(functions, gamma=0.0)\n\nnet = nn.Sequential(resnet, nn.Linear(64, 10))\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.Adam(resnet.parameters(), lr=lr_list[0])\n\ntest_error_resnet = []\nfor i in range(n_epochs):\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr_list[i]\n    optimizer.zero_grad()\n    output = resnet(X_train)\n    loss = criterion(output, y_train)\n    loss.backward()\n    optimizer.step()\n    if i % 30 == 0:\n        print(\"itr %s, loss = %.3f\" % (i, loss.item()))\n        print(\"- \" * 20)\n    _, pred = resnet(X_test).max(1)\n    test_error_resnet.append(\n        (1 - pred.eq(y_test).sum().item() / y_test.shape[0]) * 100\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the learning curves\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\nplt.semilogy(test_error_mresnet, label=\"Momentum ResNet\", color=\"red\", lw=2.5)\nplt.semilogy(test_error_resnet, label=\"ResNet\", color=\"darkblue\", lw=2.5)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Test error\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}